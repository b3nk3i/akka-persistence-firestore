
akka.persistence {

  journal {
    plugin = "firestore-journal"
    auto-start-journals = ["firestore-journal"]
  }
}

akka-persistence-firestore {

  logicalDeletion.enable = true

  client-provider-fqcn = "org.benkei.akka.persistence.firestore.client.DefaultFireStoreProvider"

  payload-serializer-fqcn = "org.benkei.akka.persistence.firestore.serialization.BinaryPayloadSerializer"

}

firestore-journal {

  class = "org.benkei.akka.persistence.firestore.journal.FirestoreJournalPlugin"

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "akka.actor.default-dispatcher"

  queue-size = "10"

  enqueue-timeout = 1s

  parallelism = 10
}

firestore-read-journal {

  class = "org.benkei.akka.persistence.firestore.query.FirestoreReadJournalProvider"

  queue-size = "10"

  enqueue-timeout = 1s

  parallelism = 10

  # EventsByTag queries (based on UUID Timestamp offset) delay to handle multiple event writes from different nodes, as each nodes generates
  # the clocks may be out of sync meaning events aren't received in order. If the events are delivered to the
  # query immediately the offset may be greater than some delayed events. Meaning that if this offset is saved
  # for restarting the query the delayed events will never be processed.
  # IMPORTANT: if this is tuned too low it may lead to events being missed in the queries and any projections
  # based on it being based on incomplete data
  eventual-consistency-delay = 5s

  # Absolute path to the write journal plugin configuration section.
  # Read journal uses event adapters from the write plugin
  # to adapt events.
  write-plugin = "firestore-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "1s"

  # The Queue buffer size where events are streamed into when pulling the journal
  # before delivering to down streams. (used by eventByTag, persistenceIds, eventsByPersistenceId)
  max-buffer-size = "500"

  # if true, queries will include logically deleted events
  # should not be configured directly, but through property akka-persistence-firestore.logicalDelete.enable
  # in order to keep consistent behavior over write/read sides
  includeLogicallyDeleted = ${akka-persistence-firestore.logicalDeletion.enable}
}


firestore-journal {

  class = "org.benkei.akka.persistence.firestore.journal.FirestoreJournalPlugin"

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "akka.actor.default-dispatcher"

  queue-size = "10"

  enqueue-timeout = 1s

  parallelism = 10
}

firestore-read-journal {

  class = "org.benkei.akka.persistence.firestore.query.FirestoreReadJournalProvider"

  queue-size = "10"

  enqueue-timeout = 1s

  parallelism = 10

  # Absolute path to the write journal plugin configuration section.
  # Read journal uses event adapters from the write plugin
  # to adapt events.
  write-plugin = "firestore-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "1s"

  # The Queue buffer size where events are streamed into when pulling the journal
  # before delivering to down streams. (used by eventByTag, persistenceIds, eventsByPersistenceId)
  max-buffer-size = "500"

  # if true, queries will include logically deleted events
  # should not be configured directly, but through property akka-persistence-firestore.logicalDelete.enable
  # in order to keep consistent behavior over write/read sides
  includeLogicallyDeleted = ${akka-persistence-firestore.logicalDeletion.enable}
}

